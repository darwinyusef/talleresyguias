# Contenido Completo del Taller MLOps con MLflow

## üìö Resumen del Taller

Este taller completo de MLOps est√° centrado 100% en **MLflow** como herramienta principal de tracking, gesti√≥n de modelos y deployment, cubriendo m√∫ltiples frameworks de ML/DL y casos de uso avanzados.

### üéØ Diferencias con otros talleres de MLOps

Este taller es √∫nico porque:
- **Foco exclusivo en MLflow**: Cada m√≥dulo profundiza en features espec√≠ficas de MLflow
- **Multi-framework**: Cubre scikit-learn, TensorFlow, PyTorch y Spark
- **Teor√≠a + Pr√°ctica**: Cada notebook incluye explicaciones te√≥ricas detalladas
- **Airflow Integration**: Orquestaci√≥n de pipelines ML completos
- **Spark para Big Data**: ML distribuido con tracking en MLflow
- **Ejemplos originales**: No reutiliza ejercicios de otros repos

---

## üìÇ Estructura Completa del Proyecto

```
mlflow-mlops-workshop/
‚îÇ
‚îú‚îÄ‚îÄ README.md                           # Descripci√≥n general del taller
‚îú‚îÄ‚îÄ GETTING_STARTED.md                  # Gu√≠a de inicio r√°pido
‚îú‚îÄ‚îÄ CONTENIDO_COMPLETO.md               # Este archivo
‚îú‚îÄ‚îÄ requirements.txt                    # Dependencias Python
‚îú‚îÄ‚îÄ setup.sh                            # Script de instalaci√≥n automatizado
‚îÇ
‚îú‚îÄ‚îÄ modulo1-sklearn/                    # ‚≠ê Fundamentos MLflow + scikit-learn
‚îÇ   ‚îú‚îÄ‚îÄ 01_mlflow_basics.ipynb         # Conceptos b√°sicos de MLflow
‚îÇ   ‚îú‚îÄ‚îÄ 02_classification_pipeline.ipynb # Pipelines de clasificaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ 03_regression_advanced.ipynb    # Regresi√≥n avanzada con regularizaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ modulo2-tensorflow/                 # ‚≠ê Deep Learning con TensorFlow/Keras
‚îÇ   ‚îú‚îÄ‚îÄ 01_cnn_image_classification.ipynb # CNNs para visi√≥n por computadora
‚îÇ   ‚îî‚îÄ‚îÄ 02_rnn_time_series.ipynb       # RNN/LSTM para series temporales
‚îÇ
‚îú‚îÄ‚îÄ modulo3-pytorch/                    # ‚≠ê PyTorch con MLflow
‚îÇ   ‚îî‚îÄ‚îÄ 01_pytorch_basics_mlflow.ipynb  # PyTorch basics + custom training loops
‚îÇ
‚îú‚îÄ‚îÄ modulo7-spark-mlflow/               # ‚≠ê ML Distribuido con Spark
‚îÇ   ‚îî‚îÄ‚îÄ 01_spark_ml_basics.ipynb       # Spark MLlib + MLflow integration
‚îÇ
‚îî‚îÄ‚îÄ modulo9-airflow-orchestration/      # ‚≠ê Orquestaci√≥n con Airflow
    ‚îú‚îÄ‚îÄ README.md                       # Documentaci√≥n de Airflow + MLflow
    ‚îú‚îÄ‚îÄ dags/
    ‚îÇ   ‚îú‚îÄ‚îÄ ml_training_pipeline.py     # Pipeline de entrenamiento automatizado
    ‚îÇ   ‚îî‚îÄ‚îÄ batch_prediction_pipeline.py # Pipeline de predicciones en batch
    ‚îú‚îÄ‚îÄ plugins/                        # (Para custom operators)
    ‚îú‚îÄ‚îÄ config/                         # (Configuraciones)
    ‚îî‚îÄ‚îÄ scripts/                        # (Scripts auxiliares)
```

---

## üìñ Detalle de Contenidos por M√≥dulo

### M√≥dulo 1: MLflow con scikit-learn (3 notebooks)

#### `01_mlflow_basics.ipynb` - Fundamentos de MLflow
**Duraci√≥n**: ~1 hora
**Teor√≠a cubierta**:
- ¬øQu√© es MLflow y por qu√© usarlo?
- 4 componentes de MLflow: Tracking, Projects, Models, Registry
- Conceptos de Run, Experiment, Artifact

**Pr√°ctica**:
- Configuraci√≥n de tracking URI
- Crear y gestionar experiments
- Logging de par√°metros con `mlflow.log_param()`
- Logging de m√©tricas con `mlflow.log_metric()`
- Logging de artefactos (gr√°ficos, archivos)
- Guardar modelos con `mlflow.sklearn.log_model()`
- Cargar modelos con `mlflow.sklearn.load_model()`
- B√∫squeda y comparaci√≥n de runs

**Datasets**: Iris, Wine

#### `02_classification_pipeline.ipynb` - Pipelines de Clasificaci√≥n
**Duraci√≥n**: ~1.5 horas
**Teor√≠a cubierta**:
- Pipelines de scikit-learn
- Preprocesamiento reproducible
- Nested runs en MLflow
- Cross-validation

**Pr√°ctica**:
- Crear pipelines con VectorAssembler + Scaler + Model
- Nested runs para experimentos jer√°rquicos
- Comparaci√≥n sistem√°tica de scalers
- Comparaci√≥n de 7 algoritmos de clasificaci√≥n
- Cross-validation con tracking
- Visualizaciones autom√°ticas
- Feature importance

**Datasets**: Breast Cancer Wisconsin
**Modelos**: LogisticRegression, DecisionTree, RandomForest, GradientBoosting, SVM, KNN, NaiveBayes

#### `03_regression_advanced.ipynb` - Regresi√≥n Avanzada
**Duraci√≥n**: ~1.5 horas
**Teor√≠a cubierta**:
- Tipos de regresi√≥n (Linear, Ridge, Lasso, ElasticNet)
- Regularizaci√≥n L1 y L2
- Modelos basados en √°rboles para regresi√≥n
- M√©tricas de regresi√≥n (MAE, MSE, RMSE, R¬≤, MAPE)
- An√°lisis de residuos

**Pr√°ctica**:
- Comparaci√≥n de m√©todos de regularizaci√≥n
- Feature selection con Lasso
- Tree-based regressors
- An√°lisis de residuos (scatter plots, histogramas, Q-Q plots)
- Feature importance tracking
- Comparaci√≥n global de modelos

**Datasets**: California Housing
**Modelos**: LinearRegression, Ridge, Lasso, ElasticNet, RandomForest, GradientBoosting, ExtraTrees

**Total M√≥dulo 1**: ~4 horas | 3 notebooks | 15+ modelos trackeados

---

### M√≥dulo 2: Deep Learning con TensorFlow/Keras (2 notebooks)

#### `01_cnn_image_classification.ipynb` - CNNs
**Duraci√≥n**: ~2 horas
**Teor√≠a cubierta**:
- Redes Neuronales Convolucionales (CNNs)
- Capas convolucionales y pooling
- Batch Normalization
- Dropout
- Data Augmentation
- Funciones de activaci√≥n

**Pr√°ctica**:
- CNN simple (2 capas conv)
- CNN avanzada (Batch Normalization + Dropout)
- Custom MLflow callbacks para logging autom√°tico
- Logging de m√©tricas por √©poca
- Confusion matrices
- Training history plots
- EarlyStopping y ReduceLROnPlateau
- ImageDataGenerator para augmentation

**Datasets**: MNIST
**Arquitecturas**: SimpleCNN, AdvancedCNN

#### `02_rnn_time_series.ipynb` - RNN/LSTM
**Duraci√≥n**: ~2 horas
**Teor√≠a cubierta**:
- Redes Neuronales Recurrentes (RNN)
- LSTM y GRU
- Vanishing gradients
- Bidirectional RNNs
- Sequence prediction
- Multi-step forecasting

**Pr√°ctica**:
- Generaci√≥n de series temporales sint√©ticas
- Preparaci√≥n de secuencias para RNN
- LSTM simple
- Stacked Bidirectional LSTM
- Multi-step forecasting
- Logging de m√©tricas por horizonte
- Visualizaci√≥n de predicciones temporales

**Datasets**: Serie temporal sint√©tica (tendencia + estacionalidad + ruido)
**Arquitecturas**: SimpleLSTM, StackedBidirectionalLSTM, MultistepLSTM

**Total M√≥dulo 2**: ~4 horas | 2 notebooks | 6+ arquitecturas de DL

---

### M√≥dulo 3: PyTorch (1 notebook)

#### `01_pytorch_basics_mlflow.ipynb` - PyTorch Fundamentals
**Duraci√≥n**: ~2 horas
**Teor√≠a cubierta**:
- PyTorch vs TensorFlow
- nn.Module
- Autograd
- Training loops expl√≠citos
- DataLoader y Dataset
- GPU acceleration

**Pr√°ctica**:
- Fully Connected Network (SimpleNN)
- Custom training loop
- Evaluation loop
- CNN con PyTorch (ConvNet)
- Learning rate scheduling
- Model checkpointing
- Logging manual de m√©tricas
- GPU/CPU device handling

**Datasets**: Fashion MNIST
**Arquitecturas**: SimpleNN, ConvNet

**Total M√≥dulo 3**: ~2 horas | 1 notebook | 2 arquitecturas PyTorch

---

### M√≥dulo 7: Spark + MLflow (1 notebook)

#### `01_spark_ml_basics.ipynb` - ML Distribuido
**Duraci√≥n**: ~2.5 horas
**Teor√≠a cubierta**:
- Apache Spark para ML
- Arquitectura distribuida
- Spark MLlib
- Pipelines de Spark
- CrossValidator para tuning distribuido

**Pr√°ctica**:
- Configuraci√≥n de SparkSession
- DataFrames distribuidos
- VectorAssembler y transformers
- Pipelines de Spark
- Comparaci√≥n de modelos distribuidos
- CrossValidator con grid search
- Logging de modelos Spark en MLflow
- Carga de modelos Spark desde MLflow

**Datasets**: Synthetic (100,000 muestras)
**Modelos**: LogisticRegression, RandomForest, GBTClassifier (Spark versions)

**Total M√≥dulo 7**: ~2.5 horas | 1 notebook | ML a escala

---

### M√≥dulo 9: Airflow Orchestration (2 DAGs)

#### `ml_training_pipeline.py` - Pipeline de Entrenamiento
**Duraci√≥n setup**: ~1 hora
**Componentes**:
- Extract: Generaci√≥n de datos
- Preprocess: Feature engineering
- Train: Entrenamiento paralelo de 3 modelos (RF, GB, LR)
- Compare: Selecci√≥n del mejor modelo
- Register: Registro en Model Registry
- Notify: Notificaciones

**Features MLflow**:
- Logging autom√°tico desde Airflow tasks
- XCom para pasar run_ids
- Registro condicional en Model Registry
- Transici√≥n a Staging basada en m√©tricas
- Nested runs desde Airflow

**Tecnolog√≠as**: Airflow + MLflow + scikit-learn

#### `batch_prediction_pipeline.py` - Predicciones en Batch
**Duraci√≥n setup**: ~1 hora
**Componentes**:
- Check model: Verificar modelo en Production/Staging
- Load model: Cargar desde MLflow
- Generate data: Datos para scoring
- Predict: Inferencia en batch
- Log predictions: Tracking de batch runs
- Quality check: Detecci√≥n de drift
- Alert: Notificaci√≥n de reentrenamiento

**Features MLflow**:
- Carga de modelos productivos
- Logging de batch predictions
- Monitoring de confianza
- Conditional workflows

**Total M√≥dulo 9**: ~2 horas setup | 2 DAGs | Orchestration completa

---

## üìä Resumen Cuantitativo del Taller

| M√©trica | Cantidad |
|---------|----------|
| **M√≥dulos** | 5 m√≥dulos principales |
| **Notebooks** | 8 notebooks interactivos |
| **DAGs de Airflow** | 2 pipelines completos |
| **Frameworks** | 4 (scikit-learn, TensorFlow, PyTorch, Spark) |
| **Modelos entrenados** | 30+ modelos diferentes |
| **Datasets** | 8 datasets distintos |
| **Horas de contenido** | 15-20 horas |
| **L√≠neas de c√≥digo** | ~5,000+ l√≠neas |
| **Teor√≠a** | Explicaciones detalladas en cada notebook |

---

## üéì Habilidades que Adquirir√°s

### Nivel B√°sico
- ‚úÖ Configurar MLflow tracking server
- ‚úÖ Crear y gestionar experiments
- ‚úÖ Logging de par√°metros, m√©tricas y artefactos
- ‚úÖ Guardar y cargar modelos
- ‚úÖ Navegar MLflow UI

### Nivel Intermedio
- ‚úÖ Pipelines reproducibles con scikit-learn
- ‚úÖ Nested runs para experimentos complejos
- ‚úÖ Custom callbacks para TensorFlow/Keras
- ‚úÖ Training loops personalizados con PyTorch
- ‚úÖ Model Registry b√°sico
- ‚úÖ Comparaci√≥n sistem√°tica de modelos

### Nivel Avanzado
- ‚úÖ Deep Learning tracking (CNN, RNN/LSTM)
- ‚úÖ ML distribuido con Spark + MLflow
- ‚úÖ Orquestaci√≥n con Airflow
- ‚úÖ Pipelines de producci√≥n
- ‚úÖ Batch predictions con monitoring
- ‚úÖ Conditional workflows
- ‚úÖ Model lifecycle management

---

## üîß Tecnolog√≠as y Herramientas

### Core MLOps
- **MLflow 2.10.2**: Tracking, Registry, Models, Projects
- **Apache Airflow 2.8.1**: Workflow orchestration
- **Apache Spark 3.5.0**: Distributed ML

### ML/DL Frameworks
- **scikit-learn 1.3.0**: ML cl√°sico
- **TensorFlow 2.15.0**: Deep Learning
- **Keras 2.15.0**: High-level DL API
- **PyTorch 2.1.2**: Deep Learning research
- **PyTorch Lightning 2.1.3**: Structured PyTorch

### Hyperparameter Tuning
- **Optuna 3.5.0**: AutoML optimization
- **Hyperopt 0.2.7**: Distributed tuning

### Boosting Libraries
- **XGBoost 2.0.3**: Gradient boosting
- **LightGBM 4.1.0**: Fast boosting
- **CatBoost 1.2.2**: Categorical boosting

### Utilities
- **Pandas 2.0.3**: Data manipulation
- **NumPy 1.24.3**: Numerical computing
- **Matplotlib 3.7.2**: Visualization
- **Seaborn 0.12.2**: Statistical viz

---

## üöÄ Quick Start (3 comandos)

```bash
cd mlflow-mlops-workshop

./setup.sh

./start_mlflow.sh
```

Abre http://localhost:5000 y empieza con `modulo1-sklearn/01_mlflow_basics.ipynb`

---

## üìà Roadmap de Aprendizaje Sugerido

### Semana 1: Fundamentos
- D√≠a 1-2: M√≥dulo 1 (scikit-learn + MLflow basics)
- D√≠a 3-4: M√≥dulo 2 (TensorFlow/Keras)
- D√≠a 5: Revisi√≥n y pr√°ctica

### Semana 2: Avanzado
- D√≠a 1-2: M√≥dulo 3 (PyTorch)
- D√≠a 3: M√≥dulo 7 (Spark)
- D√≠a 4-5: M√≥dulo 9 (Airflow)

### Semana 3: Proyecto
- Aplicar conceptos a proyecto personal
- Implementar CI/CD
- Deploy en cloud

---

## üéØ Casos de Uso Cubiertos

1. **Clasificaci√≥n binaria y multiclase**
   - Iris classification
   - Breast cancer detection
   - Fashion MNIST

2. **Regresi√≥n**
   - House price prediction
   - Feature importance analysis

3. **Computer Vision**
   - Image classification con CNNs
   - Data augmentation

4. **Time Series**
   - Forecasting con LSTM
   - Multi-step predictions

5. **Distributed ML**
   - Large-scale classification con Spark
   - Hyperparameter tuning distribuido

6. **Production Pipelines**
   - Automated training workflows
   - Batch predictions
   - Model monitoring

---

## üí° Mejores Pr√°cticas Ense√±adas

1. **Experiment Organization**
   - Naming conventions
   - Nested runs para comparaciones
   - Tags para categorizaci√≥n

2. **Reproducibilidad**
   - Logging de random seeds
   - Tracking de versions de librer√≠as
   - Pipelines determin√≠sticos

3. **Model Governance**
   - Model Registry stages
   - Version control
   - Approval workflows

4. **Performance**
   - Distributed training con Spark
   - GPU acceleration
   - Efficient data loading

5. **Production**
   - Automated pipelines
   - Monitoring y alerting
   - Conditional deployment

---

## üìö Recursos Adicionales Incluidos

- **GETTING_STARTED.md**: Gu√≠a de instalaci√≥n detallada
- **setup.sh**: Script de instalaci√≥n automatizado
- **start_mlflow.sh**: Script para iniciar MLflow (generado)
- **start_airflow.sh**: Script para iniciar Airflow (generado)
- **Documentaci√≥n inline**: Cada notebook incluye teor√≠a y explicaciones

---

## ‚ú® Caracter√≠sticas √önicas de este Taller

1. **100% MLflow-centric**: Todo gira alrededor de MLflow
2. **Multi-framework**: No te limita a un solo framework
3. **Teor√≠a integrada**: No solo c√≥digo, aprende los conceptos
4. **Ejemplos originales**: C√≥digo escrito espec√≠ficamente para este taller
5. **Producci√≥n-ready**: No solo experimentaci√≥n, tambi√©n deployment
6. **Escalable**: Desde laptop hasta cluster Spark
7. **Airflow integration**: Orquestaci√≥n real de pipelines

---

## üéì Certificaci√≥n Informal

Al completar este taller, habr√°s:

‚úÖ Trackeado 30+ modelos de ML/DL
‚úÖ Trabajado con 4 frameworks diferentes
‚úÖ Implementado pipelines de producci√≥n
‚úÖ Usado ML distribuido con Spark
‚úÖ Orquestado workflows con Airflow
‚úÖ Aplicado mejores pr√°cticas de MLOps

**¬°Est√°s listo para implementar MLflow en proyectos reales!**

---

**Autor**: MLOps Workshop Team
**Versi√≥n**: 1.0
**Fecha**: Diciembre 2024
**Licencia**: MIT

Para preguntas o contribuciones, consulta el README.md principal.
