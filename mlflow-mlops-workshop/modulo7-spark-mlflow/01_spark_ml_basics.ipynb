{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Módulo 7: Apache Spark + MLflow para ML Distribuido\n",
    "\n",
    "## Teoría: ML Distribuido con Spark\n",
    "\n",
    "### ¿Por qué Spark para ML?\n",
    "\n",
    "**Apache Spark** es un framework de procesamiento distribuido que permite:\n",
    "- Manejar datasets que no caben en memoria\n",
    "- Procesamiento paralelo en clusters\n",
    "- Escalabilidad horizontal\n",
    "- Integración con Hadoop ecosystem\n",
    "\n",
    "### Spark MLlib\n",
    "\n",
    "Biblioteca de ML de Spark con:\n",
    "- **Algoritmos distribuidos**: Regresión lineal, Random Forest, K-Means, etc.\n",
    "- **Pipelines**: Workflows de ML reproducibles\n",
    "- **Feature engineering**: Transformadores distribuidos\n",
    "- **Evaluación**: Métricas para modelos distribuidos\n",
    "\n",
    "### Arquitectura Spark\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────┐\n",
    "│          Driver Program                 │\n",
    "│  ┌────────────────────────────────┐    │\n",
    "│  │      SparkContext              │    │\n",
    "│  └────────────┬───────────────────┘    │\n",
    "└───────────────┼────────────────────────┘\n",
    "                │\n",
    "       ┌────────┴────────┐\n",
    "       │  Cluster Manager │\n",
    "       └────────┬─────────┘\n",
    "                │\n",
    "    ┌───────────┼───────────┐\n",
    "    │           │           │\n",
    " ┌──▼──┐    ┌──▼──┐    ┌──▼──┐\n",
    " │Worker│    │Worker│    │Worker│\n",
    " │      │    │      │    │      │\n",
    " │Executor│  │Executor│  │Executor│\n",
    " └──────┘    └──────┘    └──────┘\n",
    "```\n",
    "\n",
    "### Spark + MLflow\n",
    "\n",
    "**Integración poderosa**:\n",
    "1. **Spark MLlib** entrena modelos distribuidos\n",
    "2. **MLflow** trackea experimentos y registra modelos\n",
    "3. **MLflow** puede desplegar modelos Spark\n",
    "\n",
    "### Conceptos Clave de Spark\n",
    "\n",
    "#### 1. RDD (Resilient Distributed Dataset)\n",
    "```python\n",
    "rdd = sc.parallelize([1, 2, 3, 4])\n",
    "rdd.map(lambda x: x * 2).collect()\n",
    "```\n",
    "\n",
    "#### 2. DataFrame\n",
    "```python\n",
    "df = spark.read.csv(\"data.csv\", header=True)\n",
    "df.filter(df.age > 21).show()\n",
    "```\n",
    "\n",
    "#### 3. Pipeline\n",
    "```python\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[indexer, encoder, vectorizer, model])\n",
    "```\n",
    "\n",
    "## Objetivos\n",
    "- Configurar Spark con MLflow\n",
    "- ML distribuido con MLlib\n",
    "- Pipelines de Spark\n",
    "- Tracking de experimentos Spark\n",
    "- Registro de modelos Spark en MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MLflow-Spark-Workshop\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"spark-mllib-distributed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Crear Dataset Distribuido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=100000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pandas_df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(20)])\n",
    "pandas_df['label'] = y\n",
    "\n",
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "\n",
    "print(f\"Total rows: {spark_df.count():,}\")\n",
    "print(f\"Partitions: {spark_df.rdd.getNumPartitions()}\")\n",
    "spark_df.printSchema()\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pipeline de ML con Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = spark_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Train: {train_df.count():,} rows\")\n",
    "print(f\"Test: {test_df.count():,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [f'feature_{i}' for i in range(20)]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features_raw\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features_raw\",\n",
    "    outputCol=\"features\",\n",
    "    withStd=True,\n",
    "    withMean=False\n",
    ")\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    maxIter=100\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, scaler, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento con MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"spark_logistic_regression\") as run:\n",
    "    \n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"max_iter\", 100)\n",
    "    mlflow.log_param(\"train_samples\", train_df.count())\n",
    "    mlflow.log_param(\"test_samples\", test_df.count())\n",
    "    mlflow.log_param(\"num_features\", 20)\n",
    "    mlflow.log_param(\"spark_version\", spark.version)\n",
    "    \n",
    "    model = pipeline.fit(train_df)\n",
    "    \n",
    "    predictions = model.transform(test_df)\n",
    "    \n",
    "    evaluator_acc = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"label\",\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"accuracy\"\n",
    "    )\n",
    "    \n",
    "    evaluator_auc = BinaryClassificationEvaluator(\n",
    "        labelCol=\"label\",\n",
    "        rawPredictionCol=\"rawPrediction\",\n",
    "        metricName=\"areaUnderROC\"\n",
    "    )\n",
    "    \n",
    "    accuracy = evaluator_acc.evaluate(predictions)\n",
    "    auc = evaluator_auc.evaluate(predictions)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "    \n",
    "    mlflow.spark.log_model(model, \"spark_model\")\n",
    "    \n",
    "    mlflow.set_tag(\"framework\", \"Spark MLlib\")\n",
    "    mlflow.set_tag(\"distributed\", \"True\")\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparación de Modelos Distribuidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_config = [\n",
    "    {\n",
    "        \"name\": \"RandomForest\",\n",
    "        \"model\": RandomForestClassifier(\n",
    "            featuresCol=\"features\",\n",
    "            labelCol=\"label\",\n",
    "            numTrees=50,\n",
    "            maxDepth=10\n",
    "        ),\n",
    "        \"params\": {\"numTrees\": 50, \"maxDepth\": 10}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"GradientBoostedTrees\",\n",
    "        \"model\": GBTClassifier(\n",
    "            featuresCol=\"features\",\n",
    "            labelCol=\"label\",\n",
    "            maxIter=50,\n",
    "            maxDepth=5\n",
    "        ),\n",
    "        \"params\": {\"maxIter\": 50, \"maxDepth\": 5}\n",
    "    }\n",
    "]\n",
    "\n",
    "with mlflow.start_run(run_name=\"spark_model_comparison\") as parent_run:\n",
    "    \n",
    "    mlflow.set_tag(\"experiment_type\", \"model_comparison\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for config in models_config:\n",
    "        with mlflow.start_run(run_name=config[\"name\"], nested=True):\n",
    "            \n",
    "            mlflow.log_param(\"model_type\", config[\"name\"])\n",
    "            for param_name, param_value in config[\"params\"].items():\n",
    "                mlflow.log_param(param_name, param_value)\n",
    "            \n",
    "            pipeline_stages = [assembler, scaler, config[\"model\"]]\n",
    "            pipeline = Pipeline(stages=pipeline_stages)\n",
    "            \n",
    "            model = pipeline.fit(train_df)\n",
    "            \n",
    "            predictions = model.transform(test_df)\n",
    "            \n",
    "            accuracy = evaluator_acc.evaluate(predictions)\n",
    "            auc = evaluator_auc.evaluate(predictions)\n",
    "            \n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "            mlflow.log_metric(\"auc\", auc)\n",
    "            \n",
    "            mlflow.spark.log_model(model, f\"spark_{config['name']}_model\")\n",
    "            \n",
    "            results.append({\n",
    "                \"model\": config[\"name\"],\n",
    "                \"accuracy\": accuracy,\n",
    "                \"auc\": auc\n",
    "            })\n",
    "            \n",
    "            print(f\"{config['name']}: Accuracy={accuracy:.4f}, AUC={auc:.4f}\")\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nResults:\")\n",
    "    print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Tuning Distribuido con CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"spark_crossvalidation_tuning\"):\n",
    "    \n",
    "    rf = RandomForestClassifier(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\"\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(stages=[assembler, scaler, rf])\n",
    "    \n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "        .addGrid(rf.numTrees, [20, 50]) \\\n",
    "        .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "        .build()\n",
    "    \n",
    "    crossval = CrossValidator(\n",
    "        estimator=pipeline,\n",
    "        estimatorParamMaps=paramGrid,\n",
    "        evaluator=evaluator_acc,\n",
    "        numFolds=3\n",
    "    )\n",
    "    \n",
    "    mlflow.log_param(\"cv_folds\", 3)\n",
    "    mlflow.log_param(\"param_grid_size\", len(paramGrid))\n",
    "    \n",
    "    cvModel = crossval.fit(train_df)\n",
    "    \n",
    "    best_model = cvModel.bestModel\n",
    "    \n",
    "    predictions = best_model.transform(test_df)\n",
    "    \n",
    "    accuracy = evaluator_acc.evaluate(predictions)\n",
    "    auc = evaluator_auc.evaluate(predictions)\n",
    "    \n",
    "    mlflow.log_metric(\"best_accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"best_auc\", auc)\n",
    "    \n",
    "    mlflow.spark.log_model(best_model, \"best_spark_model\")\n",
    "    \n",
    "    print(f\"Best model Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Best model AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cargar y Usar Modelo Spark desde MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlflow.get_experiment_by_name(\"spark-mllib-distributed\")\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "best_run = runs.loc[runs['metrics.accuracy'].idxmax()]\n",
    "best_run_id = best_run['run_id']\n",
    "\n",
    "print(f\"Best run: {best_run['tags.mlflow.runName']}\")\n",
    "print(f\"Accuracy: {best_run['metrics.accuracy']:.4f}\")\n",
    "\n",
    "model_uri = f\"runs:/{best_run_id}/spark_model\"\n",
    "loaded_model = mlflow.spark.load_model(model_uri)\n",
    "\n",
    "sample_predictions = loaded_model.transform(test_df.limit(10))\n",
    "sample_predictions.select(\"label\", \"prediction\", \"probability\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen del Módulo 7\n",
    "\n",
    "### Conceptos Clave:\n",
    "\n",
    "1. **Spark para ML Distribuido**\n",
    "   - Procesamiento de big data\n",
    "   - ML en cluster\n",
    "   - Escalabilidad horizontal\n",
    "\n",
    "2. **Pipelines de Spark**\n",
    "   - VectorAssembler: combinar features\n",
    "   - Transformers: preprocesamiento\n",
    "   - Estimators: modelos ML\n",
    "\n",
    "3. **MLflow + Spark**\n",
    "   - `mlflow.spark.log_model()`: guardar pipelines Spark\n",
    "   - `mlflow.spark.load_model()`: cargar modelos\n",
    "   - Tracking de experimentos distribuidos\n",
    "\n",
    "4. **CrossValidator**\n",
    "   - Hyperparameter tuning distribuido\n",
    "   - Grid search paralelo\n",
    "   - K-fold CV en cluster\n",
    "\n",
    "### Ventajas de Spark + MLflow:\n",
    "- Entrenar en datasets masivos\n",
    "- Reproducibilidad en entornos distribuidos\n",
    "- Deployment de modelos Spark\n",
    "- Integración con ecosistema Hadoop\n",
    "\n",
    "## Fin del Taller\n",
    "\n",
    "¡Has completado el taller de MLOps con MLflow!\n",
    "\n",
    "### Habilidades adquiridas:\n",
    "✓ Tracking de experimentos con MLflow\n",
    "✓ ML con scikit-learn, TensorFlow, PyTorch\n",
    "✓ Deep Learning (CNN, RNN/LSTM)\n",
    "✓ Reinforcement Learning\n",
    "✓ Hyperparameter tuning\n",
    "✓ Model Registry\n",
    "✓ Orquestación con Airflow\n",
    "✓ ML distribuido con Spark\n",
    "✓ Deployment de modelos\n",
    "\n",
    "### Próximos pasos:\n",
    "1. Practica con tus propios datasets\n",
    "2. Implementa CI/CD para modelos\n",
    "3. Explora MLflow en producción\n",
    "4. Contribuye a proyectos open source"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
