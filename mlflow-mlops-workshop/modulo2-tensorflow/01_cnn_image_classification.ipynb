{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Módulo 2.1: CNN para Clasificación de Imágenes con MLflow\n",
    "\n",
    "## Teoría: Redes Neuronales Convolucionales (CNN)\n",
    "\n",
    "### ¿Qué es una CNN?\n",
    "Las Redes Neuronales Convolucionales son arquitecturas de Deep Learning especializadas en procesar datos con estructura de cuadrícula (imágenes, video, señales).\n",
    "\n",
    "### Componentes principales:\n",
    "\n",
    "1. **Capas Convolucionales (Conv2D)**\n",
    "   - Aplican filtros/kernels para detectar patrones\n",
    "   - Aprenden características jerárquicas\n",
    "   - Comparten pesos (parameter sharing)\n",
    "   - Invarianza translacional\n",
    "\n",
    "2. **Capas de Pooling**\n",
    "   - MaxPooling: toma el valor máximo\n",
    "   - AveragePooling: calcula promedio\n",
    "   - Reduce dimensionalidad\n",
    "   - Aporta invarianza a pequeñas translaciones\n",
    "\n",
    "3. **Capas Densas (Fully Connected)**\n",
    "   - Combinan features aprendidas\n",
    "   - Producen predicción final\n",
    "\n",
    "4. **Funciones de Activación**\n",
    "   - **ReLU**: $f(x) = max(0, x)$ - más común en capas intermedias\n",
    "   - **Softmax**: Para clasificación multiclase\n",
    "   - **Sigmoid**: Para clasificación binaria\n",
    "\n",
    "5. **Regularización**\n",
    "   - **Dropout**: Apaga neuronas aleatoriamente durante entrenamiento\n",
    "   - **Batch Normalization**: Normaliza activaciones\n",
    "   - **Data Augmentation**: Aumenta variedad de datos\n",
    "\n",
    "### Arquitectura típica:\n",
    "```\n",
    "Input Image\n",
    "    ↓\n",
    "[Conv2D + ReLU + Pooling] × N\n",
    "    ↓\n",
    "Flatten\n",
    "    ↓\n",
    "[Dense + ReLU + Dropout] × M\n",
    "    ↓\n",
    "Dense + Softmax\n",
    "    ↓\n",
    "Output (Predictions)\n",
    "```\n",
    "\n",
    "## Objetivos\n",
    "- Construir CNNs con TensorFlow/Keras\n",
    "- Integración completa con MLflow\n",
    "- Tracking de arquitecturas DL\n",
    "- Callbacks personalizados\n",
    "- Logging de métricas por época\n",
    "- Visualización de training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist, cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")\n",
    "print(f\"GPU disponible: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"tensorflow-cnn-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset: MNIST (Dígitos escritos a mano)\n",
    "\n",
    "Dataset clásico de 70,000 imágenes de dígitos (0-9) de 28x28 píxeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(f\"Train images: {X_train.shape}\")\n",
    "print(f\"Train labels: {y_train.shape}\")\n",
    "print(f\"Test images: {X_test.shape}\")\n",
    "print(f\"Test labels: {y_test.shape}\")\n",
    "\n",
    "print(f\"\\nClases: {np.unique(y_train)}\")\n",
    "print(f\"Rango de píxeles: [{X_train.min()}, {X_train.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 10, figsize=(15, 5))\n",
    "for i in range(30):\n",
    "    ax = axes[i // 10, i % 10]\n",
    "    ax.imshow(X_train[i], cmap='gray')\n",
    "    ax.set_title(f'Label: {y_train[i]}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('mnist_samples.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"Train images normalized: {X_train.shape}\")\n",
    "print(f\"Train labels one-hot: {y_train_cat.shape}\")\n",
    "print(f\"Pixel range after normalization: [{X_train.min():.2f}, {X_train.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelo Simple: CNN Básica\n",
    "\n",
    "Arquitectura básica:\n",
    "- Conv2D(32 filters) → MaxPooling\n",
    "- Conv2D(64 filters) → MaxPooling\n",
    "- Flatten\n",
    "- Dense(128) → Dropout\n",
    "- Dense(10, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_cnn(input_shape=(28, 28, 1), num_classes=10):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_simple_cnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom MLflow Callback\n",
    "\n",
    "Callback personalizado para logging automático de métricas en cada época"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLflowCallback(callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback personalizado para logging de métricas en MLflow\n",
    "    \"\"\"\n",
    "    def __init__(self, log_every_n_epochs=1):\n",
    "        super().__init__()\n",
    "        self.log_every_n_epochs = log_every_n_epochs\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.log_every_n_epochs == 0:\n",
    "            logs = logs or {}\n",
    "            \n",
    "            for metric_name, metric_value in logs.items():\n",
    "                mlflow.log_metric(metric_name, metric_value, step=epoch)\n",
    "            \n",
    "            print(f\"Epoch {epoch + 1}: Métricas logged to MLflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento con MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"simple_cnn_mnist\") as run:\n",
    "    \n",
    "    model = create_simple_cnn()\n",
    "    \n",
    "    optimizer = 'adam'\n",
    "    loss = 'categorical_crossentropy'\n",
    "    batch_size = 128\n",
    "    epochs = 10\n",
    "    \n",
    "    mlflow.log_param(\"model_type\", \"SimpleCNN\")\n",
    "    mlflow.log_param(\"optimizer\", optimizer)\n",
    "    mlflow.log_param(\"loss\", loss)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"epochs\", epochs)\n",
    "    mlflow.log_param(\"input_shape\", \"28x28x1\")\n",
    "    \n",
    "    total_params = model.count_params()\n",
    "    mlflow.log_param(\"total_parameters\", total_params)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    early_stopping = callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    mlflow_callback = MLflowCallback(log_every_n_epochs=1)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train_cat,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[early_stopping, mlflow_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "    \n",
    "    mlflow.log_metric(\"final_test_loss\", test_loss)\n",
    "    mlflow.log_metric(\"final_test_accuracy\", test_accuracy)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred_classes)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix - Simple CNN')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig('confusion_matrix_simple_cnn.png')\n",
    "    mlflow.log_artifact('confusion_matrix_simple_cnn.png')\n",
    "    plt.close()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    axes[0].plot(history.history['loss'], label='Train Loss')\n",
    "    axes[0].plot(history.history['val_loss'], label='Val Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    axes[1].plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=150)\n",
    "    mlflow.log_artifact('training_history.png')\n",
    "    plt.show()\n",
    "    \n",
    "    mlflow.keras.log_model(model, \"cnn_model\")\n",
    "    \n",
    "    mlflow.set_tag(\"dataset\", \"MNIST\")\n",
    "    mlflow.set_tag(\"framework\", \"TensorFlow/Keras\")\n",
    "    mlflow.set_tag(\"architecture\", \"CNN\")\n",
    "    \n",
    "    print(f\"\\nRun ID: {run.info.run_id}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Total Parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelo Avanzado: CNN con Batch Normalization\n",
    "\n",
    "Mejoras:\n",
    "- Batch Normalization después de cada Conv2D\n",
    "- Más capas convolucionales\n",
    "- Dropout adicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_cnn(input_shape=(28, 28, 1), num_classes=10):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_adv = create_advanced_cnn()\n",
    "model_adv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"advanced_cnn_mnist\") as run:\n",
    "    \n",
    "    model = create_advanced_cnn()\n",
    "    \n",
    "    lr = 0.001\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    batch_size = 128\n",
    "    epochs = 15\n",
    "    \n",
    "    mlflow.log_param(\"model_type\", \"AdvancedCNN\")\n",
    "    mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "    mlflow.log_param(\"learning_rate\", lr)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"epochs\", epochs)\n",
    "    mlflow.log_param(\"batch_normalization\", True)\n",
    "    mlflow.log_param(\"total_parameters\", model.count_params())\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    early_stopping = callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    mlflow_callback = MLflowCallback()\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train_cat,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[early_stopping, reduce_lr, mlflow_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "    \n",
    "    mlflow.log_metric(\"final_test_loss\", test_loss)\n",
    "    mlflow.log_metric(\"final_test_accuracy\", test_accuracy)\n",
    "    \n",
    "    mlflow.keras.log_model(model, \"advanced_cnn_model\")\n",
    "    \n",
    "    mlflow.set_tag(\"dataset\", \"MNIST\")\n",
    "    mlflow.set_tag(\"architecture\", \"AdvancedCNN\")\n",
    "    \n",
    "    print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Improvement over simple CNN: {(test_accuracy - 0.99)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Augmentation\n",
    "\n",
    "### Teoría: Data Augmentation\n",
    "Técnica para aumentar artificialmente el tamaño del dataset aplicando transformaciones:\n",
    "- Rotaciones\n",
    "- Desplazamientos (shifts)\n",
    "- Zoom\n",
    "- Flips horizontales/verticales\n",
    "- Cambios de brillo\n",
    "\n",
    "**Beneficios**:\n",
    "- Reduce overfitting\n",
    "- Mejora generalización\n",
    "- Hace el modelo más robusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "sample_image = X_train[0:1]\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i == 0:\n",
    "        ax.imshow(sample_image[0, :, :, 0], cmap='gray')\n",
    "        ax.set_title('Original')\n",
    "    else:\n",
    "        augmented = datagen.flow(sample_image, batch_size=1)\n",
    "        img = next(augmented)[0]\n",
    "        ax.imshow(img[:, :, 0], cmap='gray')\n",
    "        ax.set_title(f'Augmented {i}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('data_augmentation_examples.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparación de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlflow.get_experiment_by_name(\"tensorflow-cnn-classification\")\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "print(\"Comparación de modelos CNN:\")\n",
    "comparison = runs[[\n",
    "    'tags.mlflow.runName',\n",
    "    'metrics.final_test_accuracy',\n",
    "    'params.total_parameters',\n",
    "    'params.batch_size',\n",
    "    'params.epochs'\n",
    "]].sort_values('metrics.final_test_accuracy', ascending=False)\n",
    "\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen del Módulo 2.1\n",
    "\n",
    "### Conceptos Clave:\n",
    "\n",
    "1. **CNNs para Visión por Computadora**\n",
    "   - Capas convolucionales detectan patrones\n",
    "   - Pooling reduce dimensionalidad\n",
    "   - Arquitectura jerárquica\n",
    "\n",
    "2. **Técnicas de Regularización**\n",
    "   - Dropout: previene overfitting\n",
    "   - Batch Normalization: estabiliza entrenamiento\n",
    "   - Data Augmentation: aumenta datos\n",
    "\n",
    "3. **MLflow con TensorFlow/Keras**\n",
    "   - `mlflow.keras.log_model()`: guardar modelos\n",
    "   - Custom callbacks para logging automático\n",
    "   - Tracking de métricas por época\n",
    "   - Logging de arquitectura y parámetros\n",
    "\n",
    "4. **Callbacks de Keras**\n",
    "   - EarlyStopping: detiene cuando no mejora\n",
    "   - ReduceLROnPlateau: ajusta learning rate\n",
    "   - Custom MLflowCallback: logging automático\n",
    "\n",
    "### Mejores Prácticas:\n",
    "- Normalizar imágenes (0-1)\n",
    "- Usar validation split\n",
    "- Aplicar data augmentation\n",
    "- Monitorear overfitting\n",
    "- Guardar mejores pesos\n",
    "\n",
    "### Próximo Notebook:\n",
    "RNN/LSTM para series temporales"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
