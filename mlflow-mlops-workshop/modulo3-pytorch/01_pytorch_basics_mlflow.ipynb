{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Módulo 3.1: PyTorch Básico con MLflow\n",
    "\n",
    "## Teoría: PyTorch vs TensorFlow\n",
    "\n",
    "### ¿Qué es PyTorch?\n",
    "Framework de Deep Learning desarrollado por Facebook (Meta) que se ha vuelto extremadamente popular en investigación y producción.\n",
    "\n",
    "### Diferencias clave con TensorFlow:\n",
    "\n",
    "| Aspecto | PyTorch | TensorFlow/Keras |\n",
    "|---------|---------|------------------|\n",
    "| **Grafos computacionales** | Dinámicos (define-by-run) | Estáticos (define-and-run) |\n",
    "| **Debugging** | Pythonic, fácil debugging | Más complejo |\n",
    "| **Comunidad** | Investigación académica | Industria |\n",
    "| **API** | Más bajo nivel, flexible | Alto nivel (Keras) |\n",
    "| **Deployment** | TorchServe, ONNX | TF Serving, TFLite |\n",
    "\n",
    "### Ventajas de PyTorch:\n",
    "1. **Grafos dinámicos**: El grafo se construye en tiempo de ejecución\n",
    "2. **Pythonic**: Código más natural y debuggeable\n",
    "3. **Investigación**: Preferido en papers académicos\n",
    "4. **Flexibilidad**: Control total sobre el training loop\n",
    "\n",
    "### Componentes principales:\n",
    "\n",
    "#### 1. Tensors\n",
    "```python\n",
    "import torch\n",
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "```\n",
    "- Similar a NumPy arrays\n",
    "- Soporte para GPU (CUDA)\n",
    "- Autograd para diferenciación automática\n",
    "\n",
    "#### 2. nn.Module\n",
    "```python\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(10, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "```\n",
    "- Clase base para todos los modelos\n",
    "- Define arquitectura en `__init__`\n",
    "- Define forward pass en `forward()`\n",
    "\n",
    "#### 3. Autograd\n",
    "```python\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "y = x ** 2\n",
    "y.backward()\n",
    "print(x.grad)  # dy/dx = 2x = 2.0\n",
    "```\n",
    "- Diferenciación automática\n",
    "- Tracking de gradientes\n",
    "\n",
    "#### 4. Training Loop\n",
    "En PyTorch, escribes el training loop explícitamente:\n",
    "```python\n",
    "for epoch in range(epochs):\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "```\n",
    "\n",
    "## Objetivos\n",
    "- Construir modelos con PyTorch\n",
    "- Integración con MLflow\n",
    "- Custom training loops\n",
    "- GPU acceleration\n",
    "- Logging de métricas y modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"pytorch-basics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset: Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Classes: {classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelo Simple: Fully Connected Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=256, num_classes=10):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN()\n",
    "print(model)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Loop con MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"simple_nn_pytorch\") as run:\n",
    "    \n",
    "    model = SimpleNN().to(device)\n",
    "    \n",
    "    lr = 0.001\n",
    "    epochs = 10\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    mlflow.log_param(\"model_type\", \"SimpleNN\")\n",
    "    mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "    mlflow.log_param(\"learning_rate\", lr)\n",
    "    mlflow.log_param(\"epochs\", epochs)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"total_parameters\", total_params)\n",
    "    mlflow.log_param(\"device\", str(device))\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc, _, _ = evaluate(model, test_loader, criterion, device)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_acc, step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_acc, step=epoch)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    final_loss, final_acc, predictions, true_labels = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    mlflow.log_metric(\"final_test_loss\", final_loss)\n",
    "    mlflow.log_metric(\"final_test_accuracy\", final_acc)\n",
    "    \n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix - PyTorch SimpleNN')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pytorch_confusion_matrix.png')\n",
    "    mlflow.log_artifact('pytorch_confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    axes[0].plot(train_losses, label='Train Loss')\n",
    "    axes[0].plot(val_losses, label='Val Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(train_accs, label='Train Accuracy')\n",
    "    axes[1].plot(val_accs, label='Val Accuracy')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pytorch_training_history.png')\n",
    "    mlflow.log_artifact('pytorch_training_history.png')\n",
    "    plt.show()\n",
    "    \n",
    "    mlflow.pytorch.log_model(model, \"pytorch_model\")\n",
    "    \n",
    "    torch.save(model.state_dict(), 'model_weights.pth')\n",
    "    mlflow.log_artifact('model_weights.pth')\n",
    "    \n",
    "    mlflow.set_tag(\"framework\", \"PyTorch\")\n",
    "    mlflow.set_tag(\"dataset\", \"FashionMNIST\")\n",
    "    \n",
    "    print(f\"\\nFinal Test Accuracy: {final_acc:.2f}%\")\n",
    "    print(f\"Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CNN con PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 3 * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "cnn_model = ConvNet().to(device)\n",
    "print(cnn_model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in cnn_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"cnn_pytorch\") as run:\n",
    "    \n",
    "    model = ConvNet().to(device)\n",
    "    \n",
    "    lr = 0.001\n",
    "    epochs = 15\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    \n",
    "    mlflow.log_param(\"model_type\", \"ConvNet\")\n",
    "    mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "    mlflow.log_param(\"learning_rate\", lr)\n",
    "    mlflow.log_param(\"epochs\", epochs)\n",
    "    mlflow.log_param(\"scheduler\", \"StepLR\")\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc, _, _ = evaluate(model, test_loader, criterion, device)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_acc, step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_acc, step=epoch)\n",
    "        mlflow.log_metric(\"learning_rate\", optimizer.param_groups[0]['lr'], step=epoch)\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_cnn_model.pth')\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"Current LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    mlflow.log_metric(\"best_accuracy\", best_acc)\n",
    "    mlflow.pytorch.log_model(model, \"cnn_model\")\n",
    "    mlflow.log_artifact('best_cnn_model.pth')\n",
    "    \n",
    "    print(f\"\\nBest Validation Accuracy: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen del Módulo 3.1\n",
    "\n",
    "### Conceptos Clave PyTorch:\n",
    "\n",
    "1. **nn.Module**: Clase base para modelos\n",
    "2. **Training Loop**: Control explícito del entrenamiento\n",
    "3. **Autograd**: Diferenciación automática\n",
    "4. **DataLoader**: Gestión eficiente de batches\n",
    "5. **Device**: Manejo de CPU/GPU\n",
    "\n",
    "### MLflow con PyTorch:\n",
    "- `mlflow.pytorch.log_model()`: Guardar modelos\n",
    "- `mlflow.pytorch.load_model()`: Cargar modelos\n",
    "- Logging manual de métricas por época\n",
    "- Guardar state_dict para checkpoints\n",
    "\n",
    "### Próximo Notebook:\n",
    "Transfer Learning con modelos preentrenados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
