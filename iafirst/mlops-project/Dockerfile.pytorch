# Dockerfile.pytorch
FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime

# Metadata
LABEL maintainer="mlops@example.com"
LABEL version="1.0"
LABEL description="PyTorch ML Service with GPU Support"

# Argumentos de construcci贸n
ARG PYTHON_VERSION=3.11
ARG WORKDIR=/app

# Variables de entorno
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    CUDA_VISIBLE_DEVICES=0

WORKDIR ${WORKDIR}

# Instalar dependencias del sistema
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    git \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# Copiar requirements
COPY requirements.txt .

# Instalar dependencias Python
RUN pip install --upgrade pip && \
    pip install -r requirements.txt

# Copiar c贸digo de aplicaci贸n
COPY ./src ./src
COPY ./config ./config

# Crear directorios necesarios
RUN mkdir -p /app/models /app/data

# Usuario no-root para seguridad
RUN useradd -m -u 1000 mluser && \
    chown -R mluser:mluser ${WORKDIR}
USER mluser

# Healthcheck
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Puerto de exposici贸n
EXPOSE 8000

# Comando por defecto
CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
