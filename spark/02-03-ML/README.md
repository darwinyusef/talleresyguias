# ü§ñ M√≥dulo 02-03: Machine Learning con Spark MLlib + MLflow

Domina el Machine Learning distribuido a escala con Apache Spark MLlib, el motor de ML dise√±ado para procesar terabytes de datos y entrenar modelos en clusters distribuidos.

---

## üéØ Objetivos de Aprendizaje

Al completar este m√≥dulo, ser√°s capaz de:

- ‚úÖ Entender la arquitectura de Spark MLlib y c√≥mo difiere de scikit-learn
- ‚úÖ Construir pipelines de ML reproducibles y escalables
- ‚úÖ Implementar feature engineering distribuido para Big Data
- ‚úÖ Entrenar modelos supervisados (clasificaci√≥n) y no supervisados (clustering)
- ‚úÖ Evaluar modelos con m√©tricas apropiadas (AUC, Silhouette, etc.)
- ‚úÖ Trackear experimentos con MLflow para reproducibilidad
- ‚úÖ Comparar m√∫ltiples algoritmos y seleccionar el mejor
- ‚úÖ Preparar modelos para producci√≥n y serving

---

## üìö Fundamentos Te√≥ricos

### ¬øQu√© es Spark MLlib?

**Spark MLlib** (Machine Learning Library) es la librer√≠a de aprendizaje autom√°tico distribuido de Apache Spark. Est√° dise√±ada para ejecutar algoritmos de ML a escala masiva aprovechando el procesamiento paralelo de Spark.

#### Evoluci√≥n de MLlib

```
2014: spark.mllib (RDD-based API) ‚Üí Legacy, basada en RDDs
         ‚Üì
2016: spark.ml (DataFrame API) ‚Üí Moderna, recomendada
         ‚Üì
2024: spark.ml + MLflow ‚Üí Est√°ndar de producci√≥n
```

**‚ö†Ô∏è IMPORTANTE**: En este taller usamos **spark.ml** (DataFrame-based), NO `spark.mllib` (RDD-based que est√° deprecated).

---

### üîë Conceptos Clave de MLlib

#### 1. Transformers vs Estimators

Esta es la arquitectura fundamental de Spark ML:

```python
# TRANSFORMER: Transforma un DataFrame en otro
# Ejemplo: StringIndexer fitted, StandardScaler fitted
transformer.transform(df) ‚Üí nuevo_df

# ESTIMATOR: Aprende de datos y produce un Transformer
# Ejemplo: StringIndexer, StandardScaler, RandomForest
estimator.fit(df) ‚Üí transformer (modelo entrenado)
```

**Analog√≠a con scikit-learn:**
```python
# Scikit-learn
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()        # Estimator
scaler.fit(X_train)               # fit() ‚Üí devuelve self
X_scaled = scaler.transform(X)    # Transformer

# Spark MLlib
from pyspark.ml.feature import StandardScaler
scaler = StandardScaler()         # Estimator
scaler_model = scaler.fit(df)     # fit() ‚Üí devuelve Transformer
df_scaled = scaler_model.transform(df)  # Transformer
```

#### 2. Pipelines: Workflows Reproducibles

Un **Pipeline** encadena m√∫ltiples transformadores y estimadores en un flujo √∫nico:

```
Raw Data
   ‚Üì
[StringIndexer] ‚Üí indexa categor√≠as
   ‚Üì
[OneHotEncoder] ‚Üí codifica one-hot
   ‚Üì
[VectorAssembler] ‚Üí combina features en vector
   ‚Üì
[StandardScaler] ‚Üí normaliza features
   ‚Üì
[RandomForest] ‚Üí entrena modelo
   ‚Üì
Predictions
```

**Ventajas de Pipelines:**
- ‚úÖ **Reproducibilidad**: Mismo c√≥digo, mismos resultados
- ‚úÖ **No data leakage**: Las transformaciones del train no ven el test
- ‚úÖ **Deployment f√°cil**: Serializar pipeline completo como un archivo
- ‚úÖ **Hyperparameter tuning**: CrossValidator trabaja con pipelines enteros

**C√≥digo:**
```python
from pyspark.ml import Pipeline

pipeline = Pipeline(stages=[
    string_indexer,   # Estimator
    one_hot_encoder,  # Estimator
    vector_assembler, # Transformer
    scaler,           # Estimator
    classifier        # Estimator
])

# Entrenar TODO el pipeline
model = pipeline.fit(train_df)

# Usar en producci√≥n
predictions = model.transform(new_data)
```

#### 3. Vectorizaci√≥n: El Formato de MLlib

**TODOS** los algoritmos de MLlib requieren que las features est√©n en un **√∫nico vector denso o sparse**:

```python
# MAL: Features en columnas separadas
+-----+--------+----------+
| age | salary | category |
+-----+--------+----------+
|  25 |  50000 |     high |

# BIEN: Features en un vector
+--------------------+
|            features|
+--------------------+
|  [25.0, 50000.0, 1]|

# Usar VectorAssembler
from pyspark.ml.feature import VectorAssembler

assembler = VectorAssembler(
    inputCols=["age", "salary", "category_encoded"],
    outputCol="features"
)
```

**Vector Types:**
- **Dense Vector**: `[1.0, 2.0, 3.0, 4.0]` - Todos los valores almacenados
- **Sparse Vector**: `(4, [0, 2], [1.0, 3.0])` - Solo valores no-cero (eficiente)

---

### üß† Algoritmos Disponibles en MLlib

#### Clasificaci√≥n (Supervised Learning)

| Algoritmo | Cu√°ndo Usarlo | Pros | Contras |
|-----------|---------------|------|---------|
| **Logistic Regression** | Baseline r√°pido, relaciones lineales | R√°pido, interpretable | Solo lineal, requiere scaling |
| **Decision Trees** | Features categ√≥ricas, no-linealidad | No requiere scaling, interpretable | Overfitting f√°cil |
| **Random Forest** | Datasets medianos, quieres robustez | Robusto, maneja no-linealidad | Menos interpretable, lento en predicci√≥n |
| **Gradient Boosted Trees (GBT)** | M√°xima accuracy, competencias Kaggle | Muy preciso, feature importance | Lento de entrenar, hiperpar√°metros sensibles |
| **Linear SVM** | Clasificaci√≥n binaria, datos high-dimensional | Funciona bien en alta dimensi√≥n | Solo lineal, solo binario |
| **Naive Bayes** | Text classification, baseline | Muy r√°pido, funciona con poco data | Asume independencia (naive) |

#### Regresi√≥n

- Linear Regression
- Generalized Linear Regression
- Decision Tree Regressor
- Random Forest Regressor
- Gradient Boosted Trees Regressor
- Isotonic Regression

#### Clustering (Unsupervised Learning)

| Algoritmo | Uso | K requerido |
|-----------|-----|-------------|
| **K-Means** | Segmentaci√≥n de clientes, compresi√≥n | S√≠ - usar Elbow Method |
| **Bisecting K-Means** | M√°s r√°pido que K-Means, jer√°rquico | S√≠ |
| **Gaussian Mixture Model (GMM)** | Clusters con forma el√≠ptica | S√≠ |
| **LDA (Latent Dirichlet Allocation)** | Topic modeling en texto | S√≠ (n√∫mero de topics) |

---

## üî¨ Caso de Uso 1: Lead Scoring (Clasificaci√≥n)

### Problema de Negocio

**Contexto**: Una empresa B2B recibe 10,000 leads por mes. El equipo de ventas solo puede contactar 500. ¬øC√≥mo priorizamos?

**Soluci√≥n**: Modelo de ML que predice la probabilidad de conversi√≥n de cada lead.

### Datos

```python
# Dataset: lead_conversions.csv
Columns:
- id: Lead ID √∫nico
- age: Edad del prospect
- salary: Ingreso anual estimado
- web_visits: N√∫mero de visitas al sitio web
- last_action: √öltima acci√≥n (web_view, email_click, form_submit)
- converted: Target binario (0=no convirti√≥, 1=convirti√≥)
```

### Feature Engineering

#### 1. Variables Categ√≥ricas ‚Üí Num√©ricas

**String Indexing**: Convierte strings a √≠ndices num√©ricos
```python
# Antes
last_action: ["email_click", "form_submit", "web_view"]

# Despu√©s de StringIndexer
last_action_index: [0.0, 1.0, 2.0]
```

**One-Hot Encoding**: Crea features binarias
```python
# Despu√©s de OneHotEncoder
last_action_vec:
  email_click  ‚Üí [1, 0, 0]
  form_submit  ‚Üí [0, 1, 0]
  web_view     ‚Üí [0, 0, 1]
```

**¬øPor qu√© One-Hot?** Muchos algoritmos asumen que n√∫meros representan orden (0 < 1 < 2). One-hot elimina esta falsa ordenaci√≥n.

#### 2. Feature Scaling

**StandardScaler**: Normaliza features a media=0, std=1

```python
# Antes del scaling
age: [25, 45, 65]       ‚Üí rango: ~40
salary: [30000, 80000, 150000]  ‚Üí rango: ~120,000

# Problema: salary domina la distancia euclidiana
# Soluci√≥n: StandardScaler

# Despu√©s
age_scaled: [-1.0, 0.0, 1.0]
salary_scaled: [-1.0, 0.0, 1.0]
```

**‚ö†Ô∏è Cu√°ndo es CR√çTICO escalar:**
- Logistic Regression
- SVM
- K-Means
- Redes Neuronales

**Cu√°ndo NO importa:**
- Tree-based models (Random Forest, GBT, Decision Trees)

### Algoritmos Usados

#### Gradient Boosted Trees (GBT)

**C√≥mo funciona:**
1. Entrena un √°rbol d√©bil (shallow)
2. Calcula errores
3. Entrena otro √°rbol para predecir esos errores
4. Repite N veces
5. Predicci√≥n = suma de todos los √°rboles

**Hiperpar√°metros clave:**
```python
GBTClassifier(
    maxIter=20,        # N√∫mero de √°rboles (m√°s = mejor, pero overfitting)
    maxDepth=5,        # Profundidad de cada √°rbol (3-7 t√≠pico)
    stepSize=0.1,      # Learning rate (0.01-0.3)
    subsamplingRate=0.8  # Fracci√≥n de datos por √°rbol (0.5-1.0)
)
```

**Feature Importance:**
GBT produce importancia de features autom√°ticamente:
```python
model.featureImportances
# Output: [0.45, 0.30, 0.15, 0.10]
# Significa: feature 0 es 45% importante, etc.
```

### M√©tricas de Evaluaci√≥n

#### AUC-ROC (Area Under ROC Curve)

**¬øQu√© mide?** Capacidad del modelo de distinguir entre clases.

```
AUC = 1.0  ‚Üí Modelo perfecto
AUC = 0.9  ‚Üí Excelente
AUC = 0.8  ‚Üí Bueno
AUC = 0.7  ‚Üí Aceptable
AUC = 0.5  ‚Üí Aleatorio (in√∫til)
AUC < 0.5  ‚Üí Peor que aleatorio
```

**¬øPor qu√© AUC y no Accuracy?**

Ejemplo: Dataset con 95% negativos, 5% positivos
```python
# Modelo dummy que siempre predice "NO"
Accuracy = 95%  # ¬°Parece excelente!
AUC = 0.5       # Revela que es aleatorio
```

#### Matriz de Confusi√≥n

```
                 Predicted
                 No    Yes
Actual  No      TN    FP    ‚Üí Precision = TP/(TP+FP)
        Yes     FN    TP    ‚Üí Recall = TP/(TP+FN)
```

**Trade-off Precision vs Recall:**
- **High Precision**: Pocas falsas alarmas (importante en spam detection)
- **High Recall**: No perder positivos (importante en fraud detection)

**F1 Score**: Promedio arm√≥nico de Precision y Recall
```python
F1 = 2 * (Precision * Recall) / (Precision + Recall)
```

---

## üé® Caso de Uso 2: Customer Segmentation (Clustering)

### Problema de Negocio

**Contexto**: E-commerce con 100,000 clientes. Queremos segmentarlos para marketing personalizado.

**Soluci√≥n**: Clustering para descubrir grupos naturales de clientes con comportamiento similar.

### K-Means Clustering

#### Algoritmo

```
1. Inicializar K centroides aleatoriamente
2. Asignar cada punto al centroide m√°s cercano
3. Recalcular centroides como media de puntos asignados
4. Repetir 2-3 hasta convergencia
```

**Visualizaci√≥n ASCII:**
```
Iteraci√≥n 0:             Iteraci√≥n 5:
  ‚Ä¢  ‚Ä¢  ‚Ä¢  X             Clusters formados:
 ‚Ä¢  X  ‚Ä¢  ‚Ä¢              ‚ö´‚ö´‚ö´  ‚ö™‚ö™‚ö™
  ‚Ä¢  ‚Ä¢  X                ‚ö´‚ö´‚ö´  ‚ö™‚ö™‚ö™
                         üî¥üî¥üî¥
X = centroides           ‚ö´=cluster1, ‚ö™=cluster2, üî¥=cluster3
```

#### El Problema del K √ìptimo

**Elbow Method**: Graficar WSSSE vs K

```
WSSSE
  ^
  |    *
  |      *
  |        *___
  |            *____*____*
  +-----------------------> K
       ‚Üë
     "Elbow" - K √≥ptimo ‚âà 3
```

**WSSSE** = Within Set Sum of Squared Errors (menor es mejor)

#### Silhouette Score

Mide qu√© tan bien separados est√°n los clusters:

```python
Silhouette = (b - a) / max(a, b)

a = distancia promedio intra-cluster
b = distancia promedio al cluster m√°s cercano

Score:
  1.0  ‚Üí Clusters perfectamente separados
  0.5  ‚Üí Clusters razonables
  0.0  ‚Üí Clusters overlapping
  <0.0 ‚Üí Mal asignados
```

### Interpretaci√≥n de Clusters

Despu√©s de clustering, SIEMPRE analiza:

```python
# Estad√≠sticas por cluster
cluster_stats = df.groupBy("prediction").agg(
    avg("age"),
    avg("salary"),
    avg("web_visits"),
    count("*")
)

# Ejemplo de output:
Cluster 0 (35%): J√≥venes de alto engagement
  - Edad: 28 a√±os
  - Salary: $45K
  - Visitas: 35/mes
  ‚Üí Estrategia: Contenido educativo, ofertas para startups

Cluster 1 (40%): Profesionales establecidos
  - Edad: 45 a√±os
  - Salary: $95K
  - Visitas: 12/mes
  ‚Üí Estrategia: ROI demos, enterprise features

Cluster 2 (25%): Low engagement
  - Edad: 38 a√±os
  - Salary: $55K
  - Visitas: 3/mes
  ‚Üí Estrategia: Re-engagement campaigns
```

---

## üîÑ MLflow: Experiment Tracking

> üìò **Gu√≠a Completa**: Para una gu√≠a detallada de MLflow con ejemplos avanzados, instalaci√≥n paso a paso, Model Registry, y deployment en producci√≥n, consulta **[MLFLOW_GUIDE.md](./MLFLOW_GUIDE.md)**

### ¬øPor qu√© MLflow?

**Problema sin MLflow:**
```python
# Experimento 1
model_v1 = train(max_iter=10, max_depth=5)
# AUC = 0.85... pero ¬øcon qu√© par√°metros exactamente?

# 2 semanas despu√©s...
# ¬øC√≥mo reproduzco el modelo de AUC=0.85?
# ¬øQu√© features us√©?
# üò± No tengo idea
```

**Soluci√≥n con MLflow:**
```python
import mlflow

# Configurar experimento
mlflow.set_experiment("Lead_Scoring_Production")

with mlflow.start_run(run_name="GBT_v2"):
    # Log par√°metros
    mlflow.log_param("max_iter", 10)
    mlflow.log_param("max_depth", 5)
    mlflow.log_param("algorithm", "GBT")

    # Entrenar
    model = pipeline.fit(train)

    # Evaluar
    predictions = model.transform(test)
    auc = evaluator.evaluate(predictions)

    # Log m√©tricas
    mlflow.log_metric("auc", auc)
    mlflow.log_metric("accuracy", 0.82)

    # Log modelo para producci√≥n
    mlflow.spark.log_model(
        model,
        "model",
        registered_model_name="LeadScoringModel"
    )

# Resultado: Todo trackado autom√°ticamente
# UI: http://localhost:5000
```

### Inicio R√°pido con MLflow

```bash
# 1. Instalar
pip install mlflow mlflow[extras]

# 2. Iniciar UI
mlflow ui

# 3. Abrir navegador
open http://localhost:5000

# 4. Ejecutar scripts (ya integrados con MLflow)
python 02-03-ML/lead_scoring.py
python 02-03-ML/customer_segmentation.py
```

### Los 4 Componentes de MLflow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           MLflow Platform           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. Tracking                         ‚îÇ
‚îÇ    ‚îî‚îÄ Log experiments & metrics     ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ 2. Projects                         ‚îÇ
‚îÇ    ‚îî‚îÄ Package code reproducibly     ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ 3. Models                           ‚îÇ
‚îÇ    ‚îî‚îÄ Deploy to production          ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ 4. Registry                         ‚îÇ
‚îÇ    ‚îî‚îÄ Version & govern models       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Ver detalles completos en [MLFLOW_GUIDE.md](./MLFLOW_GUIDE.md)**

### Flujo de Trabajo con MLflow

```
Experimentaci√≥n
    ‚Üì
[MLflow Tracking] ‚Üí Log params, metrics, artifacts
    ‚Üì
MLflow UI ‚Üí Comparar runs
    ‚Üì
Seleccionar mejor modelo
    ‚Üì
[MLflow Registry] ‚Üí Registrar versi√≥n
    ‚Üì
Promover a "Production"
    ‚Üì
[FastAPI/Serving] ‚Üí Cargar modelo
    ‚Üì
Aplicaci√≥n en producci√≥n
```

### Cargar Modelo en Producci√≥n

```python
import mlflow

# Cargar modelo desde Registry
model_uri = "models:/LeadScoringModel/Production"
model = mlflow.spark.load_model(model_uri)

# Hacer predicciones
predictions = model.transform(new_leads_df)
```

---

## üõ†Ô∏è Scripts del M√≥dulo

### 1. `lead_scoring.py` - Clasificaci√≥n Supervisada

**Objetivo**: Predecir conversi√≥n de leads

**Flujo:**
```
1. Load data (lead_conversions.csv)
2. Exploratory Data Analysis (EDA)
3. Feature Engineering:
   - StringIndexer para last_action
   - OneHotEncoder
   - VectorAssembler
   - (Opcional) StandardScaler
4. Train 3 modelos:
   - Gradient Boosted Trees
   - Random Forest
   - Logistic Regression
5. Evaluar con 5 m√©tricas:
   - AUC, Accuracy, Precision, Recall, F1
6. Comparar modelos en MLflow
7. Seleccionar mejor modelo
8. Guardar predicciones:
   - Parquet ‚Üí data/lead_predictions.parquet
   - PostgreSQL ‚Üí tabla lead_predictions
```

**Comandos:**
```bash
# Generar datos
python scripts/generate_data.py

# Entrenar modelos
python 02-03-ML/lead_scoring.py

# Ver resultados en MLflow UI
mlflow ui
# Abrir http://localhost:5000
```

**Output esperado:**
```
üöÄ Iniciando Lead Scoring...
üìñ Cargando datos...
‚úÖ 1000 filas cargadas

üìä Tasa de conversi√≥n: 30%

üî¨ Entrenando modelos...

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
ü§ñ Entrenando: GBT
üìä Evaluaci√≥n del modelo: GBT
   AUC (ROC):      0.8234
   Accuracy:       0.7850
   Precision:      0.7456
   Recall:         0.7234
   F1 Score:       0.7343

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
ü§ñ Entrenando: RF
...

üèÜ Resumen:
GBT  -> AUC: 0.8234
RF   -> AUC: 0.8156
LR   -> AUC: 0.7923

‚úÖ Mejor modelo: GBT con AUC=0.8234
```

### 2. `customer_segmentation.py` - Clustering No Supervisado

**Objetivo**: Segmentar clientes en grupos

**Flujo:**
```
1. Load data
2. Feature selection (age, salary, web_visits)
3. StandardScaler (CR√çTICO para K-Means)
4. Elbow Method:
   - Probar K = 2, 3, 4, 5, 6
   - Calcular WSSSE y Silhouette por cada K
   - Graficar para encontrar "codo"
5. Entrenar modelo final con K √≥ptimo
6. Analizar caracter√≠sticas de cada cluster
7. Asignar nombres interpretables
8. Guardar segmentos
```

**Comandos:**
```bash
python 02-03-ML/customer_segmentation.py
```

**Output esperado:**
```
üîç Ejecutando Elbow Method...
K=2 -> Silhouette: 0.6234, WSSSE: 450000
K=3 -> Silhouette: 0.7123, WSSSE: 280000  ‚Üê Mejor
K=4 -> Silhouette: 0.6845, WSSSE: 220000
K=5 -> Silhouette: 0.6234, WSSSE: 180000

‚úÖ Mejor K=3

üéØ Entrenando modelo final con K=3...

üìä An√°lisis de Clusters:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Cluster 0: Premium (Alto valor)
   - Edad promedio: 52 a√±os
   - Salario promedio: $110,000
   - Visitas promedio: 8

Cluster 1: Engagement Alto (Potencial)
   - Edad promedio: 29 a√±os
   - Salario promedio: $45,000
   - Visitas promedio: 32

Cluster 2: Regular (Nurturing)
   - Edad promedio: 38 a√±os
   - Salario promedio: $62,000
   - Visitas promedio: 12
```

---

## üí° Mejores Pr√°cticas de ML con Spark

### 1. Train/Test Split

```python
# BIEN: Usar randomSplit con seed
train, test = df.randomSplit([0.8, 0.2], seed=42)

# MAL: Sin seed (no reproducible)
train, test = df.randomSplit([0.8, 0.2])
```

### 2. Avoid Data Leakage

```python
# BIEN: Fit en train, transform en train y test
scaler = StandardScaler()
scaler_model = scaler.fit(train_df)  # Solo aprende de train
train_scaled = scaler_model.transform(train_df)
test_scaled = scaler_model.transform(test_df)

# MAL: Fit en todo el dataset
scaler_model = scaler.fit(full_df)  # ‚ùå Data leakage!
```

### 3. Pipelines para Deployment

```python
# BIEN: Pipeline serializable
pipeline = Pipeline(stages=[indexer, encoder, assembler, model])
pipeline.fit(train).write().overwrite().save("model/")

# Cargar en producci√≥n
model = PipelineModel.load("model/")
predictions = model.transform(new_data)
```

### 4. Feature Importance

```python
# Solo para tree-based models
if hasattr(model.stages[-1], 'featureImportances'):
    importances = model.stages[-1].featureImportances
    print(f"Top feature: {importances.toArray().argmax()}")
```

### 5. Cross-Validation (para datos peque√±os-medianos)

```python
from pyspark.ml.tuning import CrossValidator, ParamGridBuilder

paramGrid = ParamGridBuilder() \
    .addGrid(gbt.maxDepth, [3, 5, 7]) \
    .addGrid(gbt.maxIter, [10, 20]) \
    .build()

cv = CrossValidator(
    estimator=pipeline,
    estimatorParamMaps=paramGrid,
    evaluator=BinaryClassificationEvaluator(),
    numFolds=3
)

cv_model = cv.fit(train)
best_model = cv_model.bestModel
```

---

## üìä Comparaci√≥n: MLlib vs Scikit-learn vs PyTorch

| Feature | Spark MLlib | Scikit-learn | PyTorch/TensorFlow |
|---------|-------------|--------------|---------------------|
| **Tama√±o de datos** | TB-PB | GB | GB (con dataloader) |
| **Distribuci√≥n** | Nativa | No (Dask parcial) | S√≠ (DDL, Horovod) |
| **Algoritmos** | ~20 core | 100+ | Deep Learning |
| **Velocidad (small data)** | Lenta (overhead) | R√°pida | Media |
| **Velocidad (big data)** | R√°pida | No cabe en RAM | Depende de GPU |
| **Deep Learning** | No | No | S√≠ |
| **Producci√≥n** | MLflow, Spark Serving | Flask, FastAPI | TorchServe, TF Serving |
| **Learning curve** | Media | Baja | Alta |

**Cu√°ndo usar cada uno:**
- **MLlib**: Datos > 100GB, features estructuradas, modelos cl√°sicos
- **Scikit-learn**: Datos < 10GB, prototipado r√°pido, algoritmos variados
- **PyTorch**: Deep learning, im√°genes, texto, series de tiempo complejas

---

## üöÄ Pr√≥ximos Pasos

Despu√©s de dominar este m√≥dulo:

1. **[M√≥dulo 04: FastAPI Serving](../04-FastAPI-Serving/README.md)**
   Sirve tus modelos via API REST

2. **[M√≥dulo 08: Streaming ML](../08-Spark-Streaming/README.md)**
   Scoring de leads en tiempo real con Kafka

3. **Avanzado: Hyperparameter Tuning**
   - CrossValidator para grid search
   - TrainValidationSplit para datasets grandes
   - Random search con MLflow

4. **Avanzado: Feature Stores**
   - Feast para feature management
   - Delta Lake para features versionadas

---

## üìö Referencias y Recursos

### Documentaci√≥n Oficial
- [Spark MLlib Guide](https://spark.apache.org/docs/latest/ml-guide.html)
- [MLlib API Docs](https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)

### Libros Recomendados
- **"Advanced Analytics with Spark"** - O'Reilly (Cap√≠tulos 3-5)
- **"Spark: The Definitive Guide"** - Cap√≠tulo 24-27 (ML)
- **"Machine Learning with PySpark"** - Pramod Singh

### Cursos Online
- [Databricks Academy - ML with Spark](https://www.databricks.com/learn/training/lakehouse-fundamentals)
- [Coursera - Big Data Analysis with Scala and Spark](https://www.coursera.org/learn/scala-spark-big-data)

### Papers
- [MLlib: Machine Learning in Apache Spark](https://arxiv.org/abs/1505.06807) - Paper original

---

## ‚ùì FAQ

**P: ¬øMLlib puede competir con XGBoost o LightGBM?**
R: En accuracy pura, no. Pero MLlib GBT es ~80-90% tan bueno y maneja 100x m√°s datos.

**P: ¬øPuedo usar modelos de scikit-learn en Spark?**
R: S√≠, con Pandas UDFs, pero pierdes distribuci√≥n. Mejor entrenar en MLlib o usar Ray.

**P: ¬øSpark MLlib soporta deep learning?**
R: Limitado. Usa TensorFlow on Spark o PyTorch Lightning para DL distribuido.

**P: ¬øC√≥mo cargo un modelo MLflow en producci√≥n?**
R: `mlflow.spark.load_model(model_uri)` o `mlflow.pyfunc.load_model()` para serving sin Spark.

**P: ¬øCu√°ntos datos necesito para que valga la pena Spark?**
R: Regla general: >50GB o >10M filas. Para menos, scikit-learn es m√°s r√°pido.

---

**¬°Comienza con el primer script! üëâ `python 02-03-ML/lead_scoring.py`**
